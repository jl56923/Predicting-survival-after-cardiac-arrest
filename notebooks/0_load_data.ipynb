{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Get pandas and postgres to work together\n",
    "import psycopg2 as pg\n",
    "import pandas as pd\n",
    "import pandas.io.sql as pd_sql\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The steps to load the required TSVs into postgres on myaws are as follows:\n",
    "\n",
    "Rename the tab-delimited files as csv files. Then secure copy them from your local folders over to your data folder on AWS.\n",
    "\n",
    "Locally in python, read in the first few lines of each file using pd.read_csv(). Then write the column names to a text file, so that you can then create the appropriate field names. Then copy those field names into a sql command to postgres to create the table you want.\n",
    "\n",
    "    scp Q1_texas_2011.csv myaws:data/\n",
    "    \n",
    "    with open('texas_discharge_columns.txt', 'w') as f:\n",
    "        for col in texas_discharge_columns:\n",
    "            f.write('%s TEXT,\\n' % col)\n",
    "\n",
    "    COPY discharges_2011 FROM '/home/ubuntu/texas_discharge_2011.csv' DELIMITER E'\\t' CSV;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PUDF_base1_1q2011_tab.txt\n",
      "PUDF_base1_2q2011_tab.txt\n",
      "PUDF_base1_3q2011_tab.txt\n",
      "PUDF_base1_4q2011_tab.txt\n",
      "Q1_texas_2011.csv\n",
      "Q2_texas_2011.csv\n",
      "Q3_texas_2011.csv\n",
      "Q4_texas_2011.csv\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "ls data/texas/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the column names for each csv file.\n",
    "Q1_head = pd.read_csv('data/texas/Q1_texas_2011.csv', sep='\\t', nrows=10)\n",
    "Q2_head = pd.read_csv('data/texas/Q2_texas_2011.csv', sep='\\t', nrows=10)\n",
    "Q3_head = pd.read_csv('data/texas/Q3_texas_2011.csv', sep='\\t', nrows=10)\n",
    "Q4_head = pd.read_csv('data/texas/Q4_texas_2011.csv', sep='\\t', nrows=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1_columns = [str(col).lower() + \" TEXT\" for col in Q1_head.columns]\n",
    "\n",
    "Q1_columns_str = \", \".join(Q1_columns)\n",
    "Q1_create_table_query = \"CREATE TABLE q1 (\" + Q1_columns_str + \")\"\n",
    "\n",
    "Q1_load_table = \"COPY q1 FROM '/home/ubuntu/data/Q1_texas_2011.csv' DELIMITER E'\\t' CSV\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2_columns = [str(col).lower() + \" TEXT\" for col in Q2_head.columns]\n",
    "\n",
    "Q2_columns_str = \", \".join(Q2_columns)\n",
    "Q2_create_table_query = \"CREATE TABLE q2 (\" + Q2_columns_str + \")\"\n",
    "\n",
    "Q2_load_table = \"COPY q2 FROM '/home/ubuntu/data/Q2_texas_2011.csv' DELIMITER E'\\t' CSV\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3_columns = [str(col).lower() + \" TEXT\" for col in Q3_head.columns]\n",
    "\n",
    "Q3_columns_str = \", \".join(Q3_columns)\n",
    "Q3_create_table_query = \"CREATE TABLE q3 (\" + Q3_columns_str + \")\"\n",
    "\n",
    "Q3_load_table = \"COPY q3 FROM '/home/ubuntu/data/Q3_texas_2011.csv' DELIMITER E'\\t' CSV\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4_columns = [str(col).lower() + \" TEXT\" for col in Q4_head.columns]\n",
    "\n",
    "Q4_columns_str = \", \".join(Q4_columns)\n",
    "Q4_create_table_query = \"CREATE TABLE q4 (\" + Q4_columns_str + \")\"\n",
    "\n",
    "Q4_load_table = \"COPY q4 FROM '/home/ubuntu/data/Q4_texas_2011.csv' DELIMITER E'\\t' CSV\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create these tables and load them, use the create_table_query strings for each quarter to creat the tables with the appropriate fields. Then, use the load_table strings to load the CSVs into the tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Postgres info to connect\n",
    "connection_args = {\n",
    "    'host': input(), # my public ip address\n",
    "    'user': 'ubuntu',    # username\n",
    "    'dbname': 'texas_discharge',   # DB that we are connecting to\n",
    "    'port': 5432         # port we opened on AWS\n",
    "}\n",
    "\n",
    "connection = pg.connect(**connection_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT * FROM q1 LIMIT 5;\"\n",
    "\n",
    "q1_sample = pd_sql.read_sql(query, connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "diag_columns = ['admitting_diagnosis']\n",
    "\n",
    "# get all the diagnosis code fields, exclude poa fields (which stands for present on arrival)\n",
    "diag_columns.extend([col for col in q1_sample.columns if 'diag_code' in col and 'poa' not in col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "diag_columns_cardiac_arrest = [col + \"='4275'\" for col in diag_columns]\n",
    "\n",
    "diag_cardiac_arrest_string = \" OR \".join(diag_columns_cardiac_arrest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's pull the subset of patients who have the diagnosis code for 'cardiac arrest' in any of their diag_column\n",
    "# fields. The diagnosis code for cardiac arrest is 427.5, which will just be 4275 in the database.\n",
    "\n",
    "cardiac_arrest_query = \"SELECT * FROM {} WHERE \" + diag_cardiac_arrest_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_cardiac_arrest_df = pd_sql.read_sql(cardiac_arrest_query.format('q1'), connection)\n",
    "\n",
    "q2_cardiac_arrest_df = pd_sql.read_sql(cardiac_arrest_query.format('q2'), connection)\n",
    "\n",
    "q3_cardiac_arrest_df = pd_sql.read_sql(cardiac_arrest_query.format('q3'), connection)\n",
    "\n",
    "q4_cardiac_arrest_df = pd_sql.read_sql(cardiac_arrest_query.format('q4'), connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3579, 194)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1_cardiac_arrest_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3149, 194)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2_cardiac_arrest_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3075, 194)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q3_cardiac_arrest_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3380, 194)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q4_cardiac_arrest_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pkls/cardiac_arrest_dfs.pkl\", \"wb\") as picklefile:\n",
    "    pickle.dump([q1_cardiac_arrest_df, q2_cardiac_arrest_df, q3_cardiac_arrest_df, q4_cardiac_arrest_df], picklefile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's try pulling the data for all the patients who had influenza. It actually might be more interesting to look at patients who were either admitted or had a principal diagnosis of influenza, rather than people who have influenza in any of their diagnoses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "adm_princ_diag = ['admitting_diagnosis', 'princ_diag_code']\n",
    "\n",
    "diag_columns_influenza = [col + \" IN ('4871','4870','4878')\" for col in adm_princ_diag]\n",
    "\n",
    "diag_influenza_string = \" OR \".join(diag_columns_influenza)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"admitting_diagnosis IN ('4871','4870','4878') OR princ_diag_code IN ('4871','4870','4878')\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diag_influenza_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "influenza_query = \"SELECT * FROM {} WHERE \" + diag_influenza_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "quarters = ['q1', 'q2', 'q3', 'q4']\n",
    "\n",
    "influenza_dfs = {}\n",
    "\n",
    "for q in quarters:\n",
    "    influenza_dfs[q] = pd_sql.read_sql(influenza_query.format(q), connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_influenza_df = pd.concat([influenza_dfs['q1'], influenza_dfs['q2'], influenza_dfs['q3'], influenza_dfs['q4']], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pkls/master_influenza_df.pkl\", \"wb\") as picklefile:\n",
    "    pickle.dump(master_influenza_df, picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'pat_status'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat_status_dict = {\n",
    "    \"01\": \"Discharged to home or self-care (routine discharge)\",\n",
    "    \"02\": \"Discharged to other short term general hospital\", \n",
    "    \"03\": \"Discharged to skilled nursing facility\",\n",
    "    \"04\": \"Discharged to intermediate care facility\",\n",
    "    \"05\": \"Discharged/transferred to a Designated Cancer Center or Children's Hospital (effective 10-1-2007)\",\n",
    "    \"06\": \"Discharged to care of home health service\",\n",
    "    \"07\": \"Left against medical advice\",\n",
    "    \"08\": \"Discharged to care of Home IV provider\",\n",
    "    \"09\": \"Admitted as inpatient to this hospital\",\n",
    "    \"20\": \"Expired\",\n",
    "    \"30\": \"Still patient\",\n",
    "    \"40\": \"Expired at home\",\n",
    "    \"41\": \"Expired in a medical facility\",\n",
    "    \"42\": \"Expired, place unknown\",\n",
    "    \"43\": \"Discharged/transferred to federal health care facility\",\n",
    "    \"50\": \"Discharged to hospice–home\",\n",
    "    \"51\": \"Discharged to hospice–medical facility\",\n",
    "    \"61\": \"Discharged/transferred within this institution to Medicare-approved swing bed\",\n",
    "    \"62\": \"Discharged/transferred to inpatient rehabilitation facility\",\n",
    "    \"63\": \"Discharged/transferred to Medicare-certified long term care hospital\",\n",
    "    \"64\": \"Discharged/transferred to Medicaid-certified nursing facility\",\n",
    "    \"65\": \"Discharged/transferred to psychiatric hospital or psychiatric distinct part of a hospital\",\n",
    "    \"66\": \"Discharged/transferred to Critical Access Hospital (CAH)\",\n",
    "    \"71\": \"Discharged/transferred to other outpatient service\",\n",
    "    \"72\": \"Discharged/transferred to institution outpatient\",\n",
    "    \"`\": \"Invalid\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_value_counts = master_influenza_df[target].value_counts()\n",
    "\n",
    "new_index = []\n",
    "\n",
    "for i in target_value_counts.index:\n",
    "    new_index.append(pat_status_dict[i])\n",
    "    \n",
    "target_value_counts.index = new_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discharged to home or self-care (routine discharge)                                                  2654\n",
       "Discharged to skilled nursing facility                                                                185\n",
       "Discharged to care of home health service                                                             166\n",
       "Discharged to intermediate care facility                                                               39\n",
       "Expired                                                                                                35\n",
       "Discharged/transferred to Medicare-certified long term care hospital                                   25\n",
       "Discharged/transferred to inpatient rehabilitation facility                                            24\n",
       "Discharged to other short term general hospital                                                        23\n",
       "Left against medical advice                                                                            14\n",
       "Discharged/transferred within this institution to Medicare-approved swing bed                          13\n",
       "Discharged/transferred to Medicaid-certified nursing facility                                          12\n",
       "Discharged to hospice–medical facility                                                                 11\n",
       "Discharged to hospice–home                                                                             10\n",
       "Discharged/transferred to a Designated Cancer Center or Children's Hospital (effective 10-1-2007)       6\n",
       "Invalid                                                                                                 4\n",
       "Discharged to care of Home IV provider                                                                  3\n",
       "Discharged/transferred to psychiatric hospital or psychiatric distinct part of a hospital               2\n",
       "Still patient                                                                                           1\n",
       "Discharged/transferred to federal health care facility                                                  1\n",
       "Name: pat_status, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_value_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3228, 194)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_influenza_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
